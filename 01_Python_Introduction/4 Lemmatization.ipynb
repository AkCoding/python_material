{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67108eaa",
   "metadata": {},
   "source": [
    "* Lemmatization is the process of finding the form of the related word in the dictionary. It is different from Stemming. It involves longer processes to calculate than Stemming. Let’s examine a definition made about this.\n",
    "\n",
    "* The aim of lemmatization, like stemming, is to reduce inflectional forms to a common base form. As opposed to stemming, lemmatization does not simply chop off inflections. Instead, it uses lexical knowledge bases to get the correct base forms of words.\n",
    "\n",
    "* NLTK provides **WordNetLemmatizer** class which is a thin wrapper around the wordnet corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "381e79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad43a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker\n",
      "beech\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize single word\n",
    "\n",
    "print(lemmatizer.lemmatize(\"workers\"))\n",
    "print(lemmatizer.lemmatize(\"beeches\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8b599",
   "metadata": {},
   "source": [
    "* Then we have a text. Let’s break this text down to tokens first. Then let’s apply the lemmatizer one by one on these tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf623a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Let', '’', 's', 'lemmatize', 'a', 'simple', 'sentence', '.', 'We', 'first', 'tokenize', 'the', 'sentence', 'into', 'words', 'using', 'nltk.word_tokenize', 'and', 'then', 'we', 'will', 'call', 'lemmatizer.lemmatize', '(', ')', 'on', 'each', 'word', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Let’s lemmatize a simple sentence. We first tokenize the sentence into words using nltk.word_tokenize and then we will call lemmatizer.lemmatize() on each word. \"\n",
    "word_list = nltk.word_tokenize(text)\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec27de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let ’ s lemmatize a simple sentence . We first tokenize the sentence into word using nltk.word_tokenize and then we will call lemmatizer.lemmatize ( ) on each word .\n"
     ]
    }
   ],
   "source": [
    "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "print(lemmatized_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83fcbe6",
   "metadata": {},
   "source": [
    "* In the first example of Lemmatizer, we used WordNet Lemmatizer from the NLTK library. Let’s do similar operations with TextBlob. As a result, we will reach similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e580e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install textblob\n",
    "\n",
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f280039a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stripe'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'stripes'\n",
    "w = Word(word)\n",
    "w.lemmatize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafd956a",
   "metadata": {},
   "source": [
    " * When we apply the ‘lemmatize’ process to the word ‘stripes’, it deletes the ‘s’ suffix and reaches the word ‘stripe’, which is the dictionary form of the word. Now let’s do the same on a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c32e7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The striped bat are hanging on their foot for best'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The striped bats are hanging on their feet for best\"\n",
    "sent = TextBlob(text)\n",
    "\" \". join([w.lemmatize() for w in sent.words])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
